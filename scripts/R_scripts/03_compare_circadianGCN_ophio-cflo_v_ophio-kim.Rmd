---
title: "Compare GCNs: ophio-cflo v ophio-kim (TC6)"
author: Biplabendu Das
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: united
    keep_md: no
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)

## For more inspiration on customizing the html output, refer to the following:
# https://bookdown.org/yihui/rmarkdown/html-document.html#table-of-contents

```

```{r housekeeping, include=FALSE}
set.seed(420)
rm(list = ls())

#' Load the libraries
pacman::p_load(pheatmap, dendextend, tidyverse, viridis)
pacman::p_load(RSQLite, tidyverse, dbplyr, DT, conflicted, WGCNA, igraph)
pacman::p_load(patchwork)

#' set conflict preference
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("layout", "plotly")
conflict_prefer("hclust", "flashClust")
conflict_prefer("simplify", "igraph")

#' set path to your working directory
path_to_repo = "/Users/biplabendudas/Documents/GitHub/Das_et_al_2022a"

# script name
script.name = "02_compare_circadianGCN_ophio-cflo_v_ophio-kim"

#' load functions
# customized theme for publication quality figures
source(paste0(path_to_repo,"/functions/theme_publication.R"))
# function to perform enrichment analysis
source(paste0(path_to_repo,"/functions/enrichment_analysis.R"))
# function to plot z-scores (Cflo genes only)
source(paste0(path_to_repo,"/functions/plot_zscores.R"))

```

## Overview/Goals

Compare the gene co-expression networks of Ophiocordyceps camponoti-floridani (Ocflo) and Ophiocordyceps kimflemingae (Okim) to:

- identify the modules that are highly conserved
- identify the modules that show no evidence for preservation

## Step 1: Identify the homologous genes

### 1.1 Load data

(A)
Dataset: Annotation file for Ocflo; contains the Okim homologs for Ocflo genes identified using blast.

*Goal: Load the homology data between O.cflo and O.kim, and filter to keep the one-to-one homologs only.*

>arb2 = O.cflo
sc16a = O.kim

- There are 7455 distinct arb2 genes in the file, and 6700 distinct cflo homologs.
- There are 6981 distinct (arb2, sc16a) maps, and multiple arb2 genes might have the same sc16a homolog.
- Get rid of the duplicates (**NEED TO JUSTIFY**); because we need to have a one-to-one mapping for O.cflo and O.kim genes for WGCNA to work without any issues.
- 6459 O.cflo genes have only one O.kim homolog; these 6459 genes will be used for further data cleanup and testing for module preservation.

```{r load_data_v1}

# Read the source file
file.name <- "FullBlast_EC05_RNAseq_orignal_copy_26Aug19.csv"
homology.dat <- 
  paste0(path_to_repo, "/data/will_et_al_2020/", file.name) %>% 
  read.csv(., stringsAsFactors = F, na.strings = c(" ","","NA"))

# Clean the source file to keep distinct gene-gene homologs
homology.dat <-
  homology.dat %>% 
  # names() %>% 
  select(arb2_gene, sc16a_gene) %>% 
  na.omit() %>% 
  distinct() %>% 
  group_by(sc16a_gene) %>% 
  filter(n()==1)

# The above names are NOT NCBI names, so let's create a separate table that contains the same
# information, but with NCBI names.

ocflo.names <- 
  paste0(path_to_repo,"/functions/func_data/ophio_cflo_annots_robin_ncbi.csv") %>% 
  read.csv(stringsAsFactors = F, na.strings = c(""," ","NA")) %>% 
  select(arb2_gene, arb2_gene_ncbi = gene_name) %>% 
  distinct()
okim.names <-
  paste0(path_to_repo,"/functions/func_data/ophio_kim_annots_robin_ncbi.csv") %>% 
  read.csv(stringsAsFactors = F, na.strings = c(""," ","NA")) %>% 
  select(sc16a_gene, sc16a_gene_ncbi = gene_name) %>% 
  distinct()
   
homology.dat.ncbi <-
  homology.dat %>% 
  left_join(ocflo.names, by="arb2_gene") %>% 
  left_join(okim.names, by = "sc16a_gene") %>%
  select(3:4) %>% 
  na.omit() # NOTE: Some of the arb2_genes do not have a ncbi gene homolog

```


(B)
Goal: Load the expression (FPKM) data for O.kim and O.cflo, and identify the "expressed" genes

- For O.cflo, 6874/7455 genes are expressed (≥1 FPKM expression for ≥6 timepoints in the day)
- Among the 6874 exp. genes, only 6014 have a okim homolog.

- For O.kim, 7864/8577 genes are expressed
- Among the 7864 exp. genes, only 6012 have a ocflo homolog.

```{r load_data_v2}

# loading database which contains data for Das and de Bekker 2022, from GitHub
db <- dbConnect(RSQLite::SQLite(), paste0(path_to_repo,"/data/databases/TC6_fungal_data.db"))

# specify sample name
sample.name <- c("ophio_cflo","ophio_kim")

# O.cflo - Expressed
#
# extract the (gene-expr X time-point) data
ocflo.dat <-
  db %>%
  tbl(., paste0(sample.name[1] ,"_fpkm")) %>%
  select(gene_name, everything()) %>%
  collect()
# count the number of time points that has ≥ 1 FPKM
n.expressed <- apply(ocflo.dat[-1], 1, function(x) sum(x >= 1))
# subset the data and only keep the filtered genes
ocflo.dat <- ocflo.dat[which(n.expressed >=6),]
#
# NEED TO THINK
# filter and keep only the ocflo genes with a okim homolog
ocflo.dat <- 
  ocflo.dat %>%
  filter(gene_name %in% homology.dat.ncbi$arb2_gene_ncbi)
  

# O.kim - Expressed + Subset
#
# extract the (gene-expr X time-point) data
okim.dat <-
  db %>%
  tbl(., paste0(sample.name[2] ,"_fpkm")) %>%
  select(gene_name, everything()) %>%
  collect()
# count the number of time points that has ≥ 1 FPKM
n.expressed <- apply(okim.dat[-1], 1, function(x) sum(x >= 1))
# subset the data and only keep the filtered genes
okim.dat <- okim.dat[which(n.expressed >=6),]
#
# NEED TO THINK
# filter and keep only the ocflo genes with a okim homolog
okim.dat <-
  okim.dat %>%
  # filter(gene_name %in% homology.dat.ncbi$sc16a_gene_ncbi) %>% 
  left_join(homology.dat.ncbi[-1], by = c("gene_name" = "sc16a_gene_ncbi")) %>% 
  filter(arb2_gene_ncbi %in% ocflo.dat$gene_name) %>% 
  select(-gene_name) %>% 
  select(gene_name = arb2_gene_ncbi, everything())

# O.cflo - Subset
#
# Finally, filter to only work with these 5850 genes
ocflo.dat <- 
  ocflo.dat %>% 
  filter(gene_name %in% okim.dat$gene_name)

```

> Note, there might be an error due to the mismatch between the lengths of the two datasets.

### 1.2 Format the data

```{r format_data}

# We work with two sets:
nSets = 2;
# For easier labeling of plots, create a vector holding descriptive names of the two sets.
setLabels = c("Ocflo", "Okim")
shortLabels = c("arb2", "sc16a")

# Form multi-set expression data: columns starting from 9 contain actual expression data.
multiExpr = vector(mode = "list", length = nSets)

multiExpr[[1]] = list(data = as.data.frame(t(log2(ocflo.dat[-c(1)]+1))));
names(multiExpr[[1]]$data) = ocflo.dat$gene_name;
rownames(multiExpr[[1]]$data) = names(ocflo.dat)[-c(1)];
multiExpr[[2]] = list(data = as.data.frame(t(log2(okim.dat[-c(1)]+1))));
names(multiExpr[[2]]$data) = okim.dat$gene_name;
rownames(multiExpr[[2]]$data) = names(okim.dat)[-c(1)];
# Check that the data has the correct format for many functions operating on multiple sets:
exprSize = checkSets(multiExpr)

# Check that all genes and samples have sufficiently low numbers of missing values.
gsg = goodSamplesGenesMS(multiExpr, verbose = 3);
gsg$allOK

```


### 1.3 Check samples

```{r check_samples}
# We now cluster the samples on their Euclidean distance, separately in each set.

sampleTrees = list()
for (set in 1:nSets) {
  sampleTrees[[set]] = hclust(dist(multiExpr[[set]]$data), method = "average")
}


# png(file = paste0(path_to_repo,"/results/temp_files/Plots/TC6_SampleClustering.png"), 
#     width = 20, height = 30, units = "cm", res = 300)
par(mfrow=c(2,1))
# par(mar = c(0, 4, 2, 0))
for (set in 1:nSets)
  plot(sampleTrees[[set]], main = paste("Sample clustering on all genes in", setLabels[set]),
       xlab="", sub="", cex = 0.7)
# dev.off()

# Define data set dimensions
nGenes = exprSize$nGenes
nSamples = exprSize$nSamples

# save(multiExpr, 
#      # Traits, 
#      nGenes, nSamples, setLabels, shortLabels, exprSize,
#      file = "TC6_Consensus-dataInput.RData")


```


### 1.4 Soft-thresholding

```{r}
# Choose a set of soft-thresholding powers
powers = c(seq(4,10,by=1), seq(12,20, by=2));
# Initialize a list to hold the results of scale-free analysis
powerTables = vector(mode = "list", length = nSets);
# Call the network topology analysis function for each set in turn
for (set in 1:nSets)
  powerTables[[set]] = list(data = pickSoftThreshold(multiExpr[[set]]$data, powerVector=powers,
                                                     verbose = 2)[[2]]);
collectGarbage();
# Plot the results:
colors = c("black", "red")
# Will plot these columns of the returned scale free analysis tables
plotCols = c(2,5,6,7)
colNames = c("Scale Free Topology Model Fit", "Mean connectivity", "Median connectivity",
             "Max connectivity");
# Get the minima and maxima of the plotted points
ylim = matrix(NA, nrow = 2, ncol = 4);
for (set in 1:nSets)
{
  for (col in 1:length(plotCols))
  {
    ylim[1, col] = min(ylim[1, col], powerTables[[set]]$data[, plotCols[col]], na.rm = TRUE);
    ylim[2, col] = max(ylim[2, col], powerTables[[set]]$data[, plotCols[col]], na.rm = TRUE);
  }
}
# Plot the quantities in the chosen columns vs. the soft thresholding power
sizeGrWindow(8, 6)
par(mfcol = c(2,2));
par(mar = c(4.2, 4.2 , 2.2, 0.5))
cex1 = 0.7;
for (col in 1:length(plotCols)) for (set in 1:nSets)
{
  if (set==1)
  {
    plot(powerTables[[set]]$data[,1], -sign(powerTables[[set]]$data[,3])*powerTables[[set]]$data[,2],
         xlab="Soft Threshold (power)",ylab=colNames[col],type="n", ylim = ylim[, col],
         main = colNames[col]);
    addGrid();
  }
  if (col==1)
  {
    text(powerTables[[set]]$data[,1], -sign(powerTables[[set]]$data[,3])*powerTables[[set]]$data[,2],
         labels=powers,cex=cex1,col=colors[set]);
  } else
    text(powerTables[[set]]$data[,1], powerTables[[set]]$data[,plotCols[col]],
         labels=powers,cex=cex1,col=colors[set]);
  if (col==1)
  {
    legend("bottomright", legend = setLabels, col = colors, pch = 20) ;
  } else
    legend("topright", legend = setLabels, col = colors, pch = 20) ;
}

```

> NOTE: Seems like I could chose either 10 or 12; going with the lower power.


### 1.5 Clustering

```{r clustering}

softPower = 10;
# Initialize an appropriate array to hold the adjacencies
adjacencies = array(0, dim = c(nSets, nGenes, nGenes))
# Calculate adjacencies in each individual data set
for (set in 1:nSets)
  adjacencies[set, , ] = abs(cor(multiExpr[[set]]$data, use = "p"))^softPower

# Initialize an appropriate array to hold the TOMs
TOM = array(0, dim = c(nSets, nGenes, nGenes));
# Calculate TOMs in each individual data set
for (set in 1:nSets)
  TOM[set, , ] = TOMsimilarity(adjacencies[set, , ])
```


### 1.6 Visualize network

```{r visualize_network_v1}
#####---#####---#####---#####---#####---#####---#####---#####---
# Visualise the networks [Foragers]
#####---#####---#####---#####---#####---#####---#####---#####---
# library(igraph)
# adj <- TOM[1,,]
# adj[adj > 0.1] = 1
# adj[adj != 1] = 0
# network <- graph.adjacency(adj)
# network <- simplify(network)  # removes self-loops
# results <- blockwiseModules(multiExpr[[1]]$data, power=softPower, TOMType="unsigned", networkType="unsigned")
# V(network)$color <- results$colors
# # par(mar=c(0,0,0,0))
# # remove unconnected nodes
# network <- delete.vertices(network, degree(network)==0)
# plot(network, layout=layout.fruchterman.reingold(network), edge.arrow.size = 0.2)
#
cmd1=cmdscale(as.dist(TOM[1,,]),2)
# sizeGrWindow(7, 6)
par(mfrow=c(1,1))
plot(cmd1, col=as.character(colorh1), main="MDS plot",
     xlab="Scaling Dimension 1", ylab="Scaling Dimension 2")
# 
# THIS CODE CHUNK DOES NOT WORK
#####---#####---#####---#####---#####---#####---#####---#####---
#####---#####---#####---#####---#####---#####---#####---#####---
```


Scaling of Topological Overlap Matrices to make them comparable across sets

```{r}
# Define the reference percentile
scaleP = 0.95

# # Set RNG seed for reproducibility of sampling
# set.seed(420)

# Sample sufficiently large number of TOM entries
nSamples = as.integer(1/(1-scaleP) * 1000);
# Choose the sampled TOM entries
scaleSample = sample(nGenes*(nGenes-1)/2, size = nSamples)
TOMScalingSamples = list();
# These are TOM values at reference percentile
scaleQuant = rep(1, nSets)
# Scaling powers to equalize reference TOM values
scalePowers = rep(1, nSets)
# Loop over sets
for (set in 1:nSets)
{
  # Select the sampled TOM entries
  TOMScalingSamples[[set]] = as.dist(TOM[set, , ])[scaleSample]
  # Calculate the 95th percentile
  scaleQuant[set] = quantile(TOMScalingSamples[[set]],
                             probs = scaleP, type = 8);
  # Scale the Ocflo TOM
  if (set>1)
  {
    scalePowers[set] = log(scaleQuant[1])/log(scaleQuant[set]);
    TOM[set, ,] = TOM[set, ,]^scalePowers[set];
  }
}
```


The array TOM now contains the scaled TOMs. To see what the scaling achieved, we form a quantile-quantile plot of the Ocflo and Okim topological overlaps before and after scaling:

```{r}
# For plotting, also scale the sampled TOM entries
scaledTOMSamples = list();
for (set in 1:nSets)
  scaledTOMSamples[[set]] = TOMScalingSamples[[set]]^scalePowers[set]
# Open a suitably sized graphics window
# sizeGrWindow(6,6)
# pdf(file = "Plots/TC5_TOMScaling-QQPlot.pdf", wi = 6, he = 6);
# qq plot of the unscaled samples
qqUnscaled = qqplot(TOMScalingSamples[[1]], TOMScalingSamples[[2]], plot.it = TRUE, cex = 0.6,
                    xlab = paste("TOM in", setLabels[1]), ylab = paste("TOM in", setLabels[2]),
                    main = "Q-Q plot of TOM", pch = 20)
# qq plot of the scaled samples
qqScaled = qqplot(scaledTOMSamples[[1]], scaledTOMSamples[[2]], plot.it = FALSE)
points(qqScaled$x, qqScaled$y, col = "red", cex = 0.6, pch = 20);
abline(a=0, b=1, col = "blue")
legend("topleft", legend = c("Unscaled TOM", "Scaled TOM"), pch = 20, col = c("black", "red"))
# dev.off();

consensusTOM = pmin(TOM[1, , ], TOM[2, , ])

# Clustering
consTree = hclust(as.dist(1-consensusTOM), method = "average");
# We like large modules, so we set the minimum module size relatively high:
minModuleSize = 30;
# Module identification using dynamic tree cut:
unmergedLabels = cutreeDynamic(dendro = consTree, 
                               distM = 1-consensusTOM,
                               deepSplit = 2, 
                               # cutHeight = 0.995,
                               minClusterSize = minModuleSize,
                               pamRespectsDendro = FALSE );
unmergedColors = labels2colors(unmergedLabels)

# To see a quick summary of the module detection, we use table(unmergedLabels):
table(unmergedLabels) # we got 35 modules

# The following code plots the consensus gene dendrogram
# together with the preliminary module colors:
sizeGrWindow(8,6)
plotDendroAndColors(consTree, unmergedColors, "Dynamic Tree Cut",
                    dendroLabels = FALSE, hang = 0.03,
                    addGuide = TRUE, guideHang = 0.05)


# Merging of modules whose expression profiles are very similar
# Calculate module eigengenes
unmergedMEs = multiSetMEs(multiExpr, colors = NULL, universalColors = unmergedColors)
# Calculate consensus dissimilarity of consensus module eigengenes
consMEDiss = consensusMEDissimilarity(unmergedMEs);
# Cluster consensus modules
consMETree = hclust(as.dist(consMEDiss), method = "average");
# Plot the result
sizeGrWindow(7,6)
par(mfrow = c(1,1))
plot(consMETree, main = "Consensus clustering of consensus module eigengenes",
     xlab = "", sub = "")
abline(h=0.25, col = "red")

merge = mergeCloseModules(multiExpr, unmergedLabels, cutHeight = 0.25, verbose = 3)

# Numeric module labels
moduleLabels = merge$colors;
# Convert labels to colors
moduleColors = labels2colors(moduleLabels)
# Eigengenes of the new merged modules:
consMEs = merge$newMEs;

sizeGrWindow(9,6)
plotDendroAndColors(consTree, cbind(unmergedColors, moduleColors),
                    c("Unmerged", "Merged"),
                    dendroLabels = FALSE, hang = 0.03,
                    addGuide = TRUE, guideHang = 0.05)

# # Save all relevant data from Part II
# save(consMEs, moduleColors, moduleLabels, consTree, file = "TC6_Consensus-NetworkConstruction-man.RData")

```

